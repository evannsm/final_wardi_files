{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from typing import Any, Callable, Sequence\n",
    "from jax import random\n",
    "import jax\n",
    "from flax import serialization\n",
    "import jax.numpy as jnp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "with open(\"sim_params.bin\", \"rb\") as f:\n",
    "    loaded_bytes = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = np.array([ 2.49944982,  1.60042476, -1.90054772, -0.09470656,  0.61739224,\n",
    "        0.64762334,  0.17935197,  0.13538294, -0.05906635, 11.50631109,\n",
    "        0.67154372,  0.71453788,  0.81230723])\n",
    "\n",
    "INPUT = np.array([ 1.87724153,  2.57925116, -0.31868312,  0.59077944])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardLoad(nn.Module):\n",
    "  features: Sequence[int]\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs):\n",
    "    x = inputs\n",
    "    for i, feat in enumerate(self.features):\n",
    "    #   print(f\"{i = }, {feat = }\")\n",
    "      x = nn.Dense(feat, name=f'layers_{i}')(x)\n",
    "      if i != len(self.features) - 1:\n",
    "        x = nn.relu(x)\n",
    "    return x\n",
    "\n",
    "modelnew = FeedForwardLoad(features=[13, 128, 256, 256, 128, 4])\n",
    "\n",
    "key1, key2 = random.split(random.key(0), 2)\n",
    "x = STATE\n",
    "init_params = modelnew.init(key2, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore parameters from bytes\n",
    "loaded_params = serialization.from_bytes(init_params, loaded_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50k_iris_sim.npy because sim is True\n"
     ]
    }
   ],
   "source": [
    "sim = True\n",
    "data_all = np.load('50k_iris_sim.npy' if sim else '50k_holybro.npy' )\n",
    "print(f\"Loaded {'50k_iris_sim.npy' if sim else '50k_holybro.npy'} because sim is {sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader.dataset.data.shape = (40000, 17)\n",
      "test_dataloader.dataset.data.shape = (10000, 17)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "class QuadrotorDataset(Dataset):\n",
    "  def __init__(self, state_size = 9, ctrlinput_size = 4, training=True, data_all = data_all):\n",
    "    self.input_size = state_size + ctrlinput_size\n",
    "    self.output_size = ctrlinput_size\n",
    "    np.random.shuffle(data_all)\n",
    "    train_size = int(len(data_all)*0.8)\n",
    "    if training:\n",
    "      self.data = data_all[0:train_size]\n",
    "    else:\n",
    "      self.data = data_all[train_size:]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    inputs = self.data[idx, 0: self.input_size]\n",
    "    outputs = self.data[idx, self.input_size:]\n",
    "    return torch.FloatTensor(inputs), torch.FloatTensor(outputs).view(4)\n",
    "  \n",
    "train_dataset = QuadrotorDataset(training=True)\n",
    "test_dataset = QuadrotorDataset(training=False)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"{train_dataloader.dataset.data.shape = }\")\n",
    "print(f\"{test_dataloader.dataset.data.shape = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.0019400252\n",
      "Test Loss:  0.0017135364\n",
      "Test Loss:  0.0014636364\n",
      "Test Loss:  0.0017905764\n",
      "Test Loss:  0.0017181349\n",
      "Test Loss:  0.001804505\n",
      "Test Loss:  0.0016288267\n",
      "Test Loss:  0.0018577299\n",
      "Test Loss:  0.001627598\n",
      "Test Loss:  0.0017183679\n",
      "Test Loss:  0.0018232509\n",
      "Test Loss:  0.0019828733\n",
      "Test Loss:  0.0019792053\n",
      "Test Loss:  0.0017084738\n",
      "Test Loss:  0.0018759171\n",
      "Test Loss:  0.0018061978\n",
      "Test Loss:  0.0018558702\n",
      "Test Loss:  0.0019150736\n",
      "Test Loss:  0.0018489601\n",
      "Test Loss:  0.0017837841\n",
      "Test Loss:  0.0015791996\n",
      "Test Loss:  0.0015917886\n",
      "Test Loss:  0.0017853761\n",
      "Test Loss:  0.00181926\n",
      "Test Loss:  0.0017519521\n",
      "Test Loss:  0.0019155019\n",
      "Test Loss:  0.001638169\n",
      "Test Loss:  0.002171372\n",
      "Test Loss:  0.0016295933\n",
      "Test Loss:  0.0018101349\n",
      "Test Loss:  0.0019726965\n",
      "Test Loss:  0.0018853527\n",
      "Test Loss:  0.001667918\n",
      "Test Loss:  0.0019204024\n",
      "Test Loss:  0.0022012452\n",
      "Test Loss:  0.0017729761\n",
      "Test Loss:  0.001711145\n",
      "Test Loss:  0.0015479433\n",
      "Test Loss:  0.0020177239\n",
      "Test Loss:  0.0018045647\n",
      "Test Loss:  0.002017832\n",
      "Test Loss:  0.001779635\n",
      "Test Loss:  0.001719031\n",
      "Test Loss:  0.0024004846\n",
      "Test Loss:  0.0016140981\n",
      "Test Loss:  0.0018103702\n",
      "Test Loss:  0.0017994132\n",
      "Test Loss:  0.0018470901\n",
      "Test Loss:  0.0018315697\n",
      "Test Loss:  0.0020542718\n",
      "Test Loss:  0.0016673176\n",
      "Test Loss:  0.0017490169\n",
      "Test Loss:  0.0018896856\n",
      "Test Loss:  0.0016919933\n",
      "Test Loss:  0.0016916601\n",
      "Test Loss:  0.001675168\n",
      "Test Loss:  0.0017234334\n",
      "Test Loss:  0.0020338143\n",
      "Test Loss:  0.0014118672\n",
      "Test Loss:  0.0017010634\n",
      "Test Loss:  0.0017325485\n",
      "Test Loss:  0.0019569458\n",
      "Test Loss:  0.0016653917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.001703923\n",
      "Test Loss:  0.0019247064\n",
      "Test Loss:  0.001674507\n",
      "Test Loss:  0.0019294166\n",
      "Test Loss:  0.0018371665\n",
      "Test Loss:  0.0017438885\n",
      "Test Loss:  0.0017160224\n",
      "Test Loss:  0.0024745523\n",
      "Test Loss:  0.0016715796\n",
      "Test Loss:  0.0019238127\n",
      "Test Loss:  0.0018227017\n",
      "Test Loss:  0.0017470929\n",
      "Test Loss:  0.0018098522\n",
      "Test Loss:  0.0017143105\n",
      "Test Loss:  0.0019217604\n",
      "Test Loss:  0.0016020726\n",
      "Mean Test Loss:  0.0018065559\n"
     ]
    }
   ],
   "source": [
    "test_array = []\n",
    "@jax.jit\n",
    "def mse(params, x_batched, y_batched):\n",
    "    pred = modelnew.apply(params, x_batched)\n",
    "    SE = (pred - y_batched)**2\n",
    "    return jnp.mean(SE)\n",
    "\n",
    "for data in test_dataloader:\n",
    "    x_samples, y_samples = data\n",
    "    x_samples = jnp.array(x_samples.numpy())  # Convert to jax.numpy array\n",
    "    y_samples = jnp.array(y_samples.numpy())  # Convert to jax.numpy array\n",
    "    loss_val  = mse(loaded_params, x_samples, y_samples)\n",
    "    print('Test Loss: ', loss_val)\n",
    "    test_array.append(loss_val)\n",
    "print('Mean Test Loss: ', np.mean(test_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Compiled NN Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def model_apply(params, state, ctrl):\n",
    "    x = jnp.concatenate((state, ctrl))\n",
    "    return modelnew.apply(params, x)\n",
    "apply_model = jax.jit(partial(model_apply, loaded_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference time:  0.007016882300376892\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_log = []\n",
    "for i in range(16):\n",
    "    x_samples, y_samples = data\n",
    "    state1 = x_samples[i, 0:9]\n",
    "    state1 = jnp.array(state1.numpy())\n",
    "    ctrl1 = x_samples[i, 9:]\n",
    "    ctrl1 = jnp.array(ctrl1.numpy())\n",
    "\n",
    "    t0 = time.time()\n",
    "    apply_model(state1, ctrl1)\n",
    "    time_log.append(time.time() - t0)\n",
    "\n",
    "print('Mean inference time: ', np.mean(time_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import jacfwd\n",
    "\n",
    "@jax.jit\n",
    "def compute_jacobian(state, ctrl):\n",
    "    return jacfwd(lambda x: apply_model(state, x))(ctrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean jacobian computation time:  0.007231995463371277\n"
     ]
    }
   ],
   "source": [
    "jacobian_time_log = []\n",
    "\n",
    "for i in range(16):\n",
    "    x_samples, y_samples = data\n",
    "    state1 = x_samples[i, 0:9]\n",
    "    state1 = jnp.array(state1.numpy())\n",
    "    ctrl1 = x_samples[i, 9:]\n",
    "    ctrl1 = jnp.array(ctrl1.numpy())\n",
    "\n",
    "    t0 = time.time()\n",
    "    jac = compute_jacobian(state1, ctrl1)\n",
    "    jacobian_time_log.append(time.time() - t0)\n",
    "\n",
    "print('Mean jacobian computation time: ', np.mean(jacobian_time_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.00417626,  0.09946538, -0.36449325, -0.09978978],\n",
       "       [ 0.01697065,  0.30175763,  0.06594227, -0.00204584],\n",
       "       [-0.15662749,  0.04095466, -0.02830148, -0.010667  ],\n",
       "       [-0.0039165 ,  0.02387397,  0.03821919,  0.8509513 ]],      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
